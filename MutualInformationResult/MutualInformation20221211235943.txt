			Calculo de la Información Mutua

Datos de la matriz de probabilidad apriori = 
| 0.8 0.2 |
| 0.7 0.3 |

Datos del vector de probabilidad aporteriori
{0.6, 0.4}

Probabilidad Conjunta
P(X = X0,Y = Y0) = P(Y = Y0|X = X0P(X = X0 = 0.8 * 0.6 = 0.48
P(X = X0,Y = Y1) = P(Y = Y1|X = X0P(X = X0 = 0.2 * 0.6 = 0.12
P(X = X1,Y = Y0) = P(Y = Y0|X = X1P(X = X1 = 0.7 * 0.4 = 0.28
P(X = X1,Y = Y1) = P(Y = Y1|X = X1P(X = X1 = 0.3 * 0.4 = 0.12
Sumatoria de probabilidad conjunta = 1.0

Probabilidad Marginal
P(Y = Y0)
P(X = X0, Y = Y0) = 0.48
P(X = X1, Y = Y0) = 0.28
P(Y = Y0) = 0.76

P(Y = Y1)
P(X = X0, Y = Y1) = 0.12
P(X = X1, Y = Y1) = 0.12
P(Y = Y1) = 0.24

Sumatoria de probabilidad marginal = 1.0

Calculo de H(y)
0.76 * Log2(1/0.76) = 0.3009057940116659
0.24 * Log2(1/0.24) = 0.4941344853728565
Sumatoria de Hy = 0.8

Calculo de H(y|h)
0.48 * Log2(1/0.8) = 0.15452548554593393
0.12 * Log2(1/0.2) = 0.2786313713864835
0.28 * Log2(1/0.7) = 0.1440804883923323
0.12 * Log2(1/0.3) = 0.20843587129994476
Sumatoria de H(y|h) = 0.79

Informacion Mutua Resultante = 0.01
